{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba9b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # untar the file source\n",
    "# import tarfile\n",
    "\n",
    "# file_path = \"dataset/liputan6_data.tar.gz\"\n",
    "\n",
    "# with tarfile.open(file_path, \"r:gz\") as tar:\n",
    "#     print(\"Contents of the tar.gz archive:\")\n",
    "#     for member in tar.getmembers():\n",
    "#         print(member.name)\n",
    "\n",
    "# tf = tarfile.open(file_path)\n",
    "# tf.extractall('dataset/')\n",
    "\n",
    "\n",
    "### References\n",
    "# - add data_rate_limit in jupyter notebook: https://stackoverflow.com/questions/43490495/how-to-set-notebookapp-iopub-data-rate-limit-and-others-notebookapp-settings-in\n",
    "# - how to extract and unzip tar.gz file: https://www.youtube.com/watch?v=GCnSR1X_zwc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04442c5-6be0-4957-8a68-929bb4a37d65",
   "metadata": {},
   "source": [
    "# About the Project\n",
    "### 1. Objective\n",
    "Mengembangkan sistem berbasis AI untuk meringkas dokumen dengan metode text understanding yang dapat memperoleh gagasan utama dari suatu berita.\n",
    "Untuk mencapai target tersebut dapat menggunakan model BERT. Setelah pengembangan model, dapat dilakukan model evaluation dan penarikan kesimpulan. Setelah proyek telah selesai, yang tak kalah penting adalah tahap publish di repo Github.\n",
    "### 2. Text Summarization\n",
    "Metode komputasi yang digunakan untuk merangkum text menjadi ringkasan yang lebih singkat namun tetap mempertahankan poin kunci, frasa, dan konteks teks tersebut. Sehingga didapatkan teks dalam bentuk yang lebih ringkas dan padat.\n",
    "### 3. Dataset\n",
    "Dataset yang digunakan adalah kumpulan data summarization dari website Liputan6.\n",
    "Setiap data memuat informasi berikut:\n",
    "1. id\n",
    "2. url\n",
    "3. clean_article\n",
    "4. clean_summary\n",
    "5. extractive_summary\n",
    "\n",
    "#### 3.1. about **id_liputan6** Dataset\n",
    "Obtain 215,827 document-summary pairs to develop benchmark model for extractive and abstractive summarization with multilingual and monolingual BERT-based models. \n",
    "\n",
    "The dataset covers various topics and events from October 2000 to October 2010.\n",
    "To summarize the paper covers some results as below:\n",
    "1. release a large-scale Indonesia Summarization corpus with over 200K documents, which is larger magnitude than current dataset.\n",
    "2. Statistics to show  that the summary in the dataset are reasonably abstractive and provide test partitions (standard and extreme abstractive test set).\n",
    "3. Develop benchmark extractive and abstractive summarization models based on pre-trained BERT models\n",
    "4. Conduct error analysis for future research on Indonesia Text summarization\n",
    "\n",
    "The dataset covers various topics and events from October 2000 to October 2010. Those topics such as:\n",
    "1. Politics\n",
    "2. Business\n",
    "3. Sport\n",
    "4. Technology\n",
    "5. Health\n",
    "6. Entertainment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "804054f5-f6ce-4674-994a-1134db271e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, DownloadConfig, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8196a705-8551-443e-a28d-2eb1e705a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and and use some configs\n",
    "# canonical subset\n",
    "\n",
    "DATA_DIR = \"dataset/liputan6_data/\"\n",
    "download_config = DownloadConfig(delete_extracted=True)\n",
    "dataset = load_dataset(\n",
    "        \"id_liputan6\",\n",
    "        \"canonical\",\n",
    "        data_dir = DATA_DIR,\n",
    "    download_config = download_config\n",
    "        )\n",
    "\n",
    "# xtreme subset\n",
    "# dataset_xtreme = load_dataset(\n",
    "#         \"id_liputan6\",\n",
    "#         \"xtreme\",\n",
    "#         data_dir = DATA_DIR,\n",
    "#     download_config = download_config\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d39d0d-fe83-4052-bdc8-3b495f899818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'url', 'clean_article', 'clean_summary', 'extractive_summary'],\n",
       "        num_rows: 10972\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'url', 'clean_article', 'clean_summary', 'extractive_summary'],\n",
       "        num_rows: 10972\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'clean_article', 'clean_summary', 'extractive_summary'],\n",
       "        num_rows: 193883\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1ebf24-cd9f-46e1-b326-382df65a6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_text = dataset['train'].shuffle(seed=42).select(range(2))\n",
    "sample_eval_text = dataset['validation'].shuffle(seed=42).select(range(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72733a66-8f6d-4c3f-8c6b-9e197a86648a",
   "metadata": {},
   "source": [
    "## Combine Performance between pre-trained model **cahya/bert2gpt-indonesian-summarization** and **cahya/t5-base-indonesian-summarization-cased**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496b8eea-24cb-42bf-8d63-f40b603162e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def generate_summaries(model, tokenizer, article):\n",
    "    input_ids = tokenizer.encode(article, truncation=True, max_length = 512, return_tensors='pt')\n",
    "    summary_ids = model.generate(\n",
    "                input_ids,\n",
    "                min_length=20,\n",
    "                max_length=80, \n",
    "                num_beams=10,\n",
    "                repetition_penalty=2.5, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2,\n",
    "                use_cache=True,\n",
    "                do_sample = True,\n",
    "                temperature = 0.8,\n",
    "                top_k = 50,\n",
    "                top_p = 0.95\n",
    "            )\n",
    "    summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary_text\n",
    "\n",
    "def eval_perf_models(model, tokenizer):\n",
    "    summaries = []\n",
    "    for article in tqdm((sample_train_text[\"clean_article\"]), total= len(sample_train_text[\"clean_article\"])):\n",
    "        summary_text = generate_summaries(model, tokenizer, article)\n",
    "        summaries.append(summary_text)\n",
    "\n",
    "    # calculate ROUGE\n",
    "    rouge = load_metric(\"rouge\")\n",
    "    # rouge_metric =evaluate.load(\"precision\")\n",
    "    \n",
    "    rouge_names = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "    \n",
    "    rouge.add_batch(predictions = summaries, references = sample_train_text[\"clean_summary\"])\n",
    "    score = rouge.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    df_eval = pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"score\"])\n",
    "\n",
    "    return df_eval, summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e4963-11a7-41a9-a036-0518f528fa5f",
   "metadata": {},
   "source": [
    "### BERT2GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d577fe90-cd5e-46a9-9164-0e5119711b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:16<00:00, 38.07s/it]\n",
      "C:\\Users\\achma\\AppData\\Local\\Temp\\ipykernel_22080\\2774803115.py:32: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric(\"rouge\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>0.485266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>0.320056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>0.467085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>0.467085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "rouge1     0.485266\n",
       "rouge2     0.320056\n",
       "rougeL     0.467085\n",
       "rougeLsum  0.467085"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = 'cahya/bert2gpt-indonesian-summarization'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "tokenizer.eos_token = tokenizer.sep_token\n",
    "model = EncoderDecoderModel.from_pretrained(MODEL_PATH).to(device)\n",
    "\n",
    "df_eval_bert2gpt, summaries_bert2gpt = eval_perf_models(model = model, tokenizer=tokenizer)\n",
    "df_eval_bert2gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04f5bb4-e4c1-4a04-8202-55227c3396b6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a517c3a6-aed6-463b-9e8c-19381bd68a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241c7276058d4840a00a42f8323bec74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\personal_project\\NLP-101\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\achma\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:37<00:00, 18.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>0.471869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>0.309764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>0.454325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>0.454325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "rouge1     0.471869\n",
       "rouge2     0.309764\n",
       "rougeL     0.454325\n",
       "rougeLsum  0.454325"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = 'cahya/t5-base-indonesian-summarization-cased'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_PATH)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_PATH)\n",
    "\n",
    "df_eval_t5, summaries_t5 = eval_perf_models(model = model, tokenizer=tokenizer)\n",
    "df_eval_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbf95757-3a1d-424f-9ba8-4ca502988c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGINAL TEXT</th>\n",
       "      <th>REFERENCE</th>\n",
       "      <th>BERT2GPT</th>\n",
       "      <th>T5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liputan6.com, Solok: Hingga Rabu (24/10), lebih dari 10 sumur warga di Jorong Tanjung Harapan Nagari Sungai Nanam, Solok, Sumatra Barat, telah tercemar belerang. Hasil penelitian tim Dinas Pertambangan dan Energi Sumbar, pencemaran diakibatkan keluarnya udara panas dari magma Gunung Talang pascagempa 12 September silam. Warga tak berani memakai air untuk kebutuhan sehari-hari karena khawatir keracunan. Dinas Pertambangan dan Energi Sumbar bersama tim Vulkanologi dan Mitigasi Bencana Geologi Bandung masih meneliti penyebab keluarnya hawa panas tersebut. Udara panas bersuhu 61 derajat Celcius dan berbau belerang itu keluar dari lantai rumah milik tiga warga. Saat ini, ketiga rumah itu sudah dikosongkan dan diberi garis polisi [baca: Gunung Talang Mengeluarkan Hawa Panas Beracun]. (YNI/Denni Risman dan Arset Kusnadi).</td>\n",
       "      <td>Air sumur warga Tanjung Harapan Nagari Sungai Nanam, Kabupaten Solok, Sumbar, mulai tercemar belerang. Diduga, pencemaran diakibatkan keluarnya udara panas dari magma Gunung Talang di kawasan itu.</td>\n",
       "      <td>sekitar 10 sumur warga di jorong tanjung harapan nagari sungai nanam, solok, sumbar, tercemar belerang. pencemaran diakibatkan keluarnya udara panas dari magma gunung talang pascagempa 12 september silam.</td>\n",
       "      <td>Lebih dari 10 sumur warga di Jorong Tanjung Harapan Nagari Sungai Nanam, Solok, Sumbar, telah tercemar belerang. Pencemaran diakibatkan keluarnya udara panas dari magma Gunung Talang pascagempa 12 September silam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liputan6.com, Barcelona: Setelah mengalami musim yang buruk pada tahun pertamanya di Spanyol, Thierry Henry membuktikan dirinya masih bertaji. Di bawah pelatih Pep Guardiola sinarnya kembali terang. Titi, panggilan akrabnya, banyak membantu Barcelona menyabet tiga gelar juara bergengsi plus juara Piala Dunia Antarklub di Jepang, Desember silam. Namun begitu, di musim kompetisi sekarang sinar Henry kembali redup. Cedera merongrong membuatnya tidak banyak mendapat kesempatan bermain. Insiden handball ketika membela Prancis yang menyebabkan gol ke gawang Republik Irlandia di babak play-off Piala Dunia 2010 semakin menenggelamkan namanya. Itu semua bermuara pada kabar bahwa dirinya akan hengkang dari Nou Camp, markas Barcelona, setelah perhelatan PD 2010 di Afrika Selatan. Amerika Serikat menjadi persinggahan berikut yang diyakini menjadi pilihan Henry. Kabar itu kian santer kini dan bahkan dikabarkan harian olahraga Katalan, penyerang legendaris Arsenal ini sudah menandatangani prakontrak dengan klub Major League Soccer atau Liga Utama AS, New York Red Bulls. (DIM/Sport).</td>\n",
       "      <td>Thierry Henry dikabarkan sudah menandatangani prakontrak dengan klub di Amerika Serikat, New York Red Bulls.</td>\n",
       "      <td>thierry henry membuktikan dirinya masih bertaji. di bawah pelatih pep guardiola sinarnya kembali terang.</td>\n",
       "      <td>Thierry Henry membuktikan dirinya masih bertaji. Di bawah bimbingan Pep Guardiola sinarnya kembali redup.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ORIGINAL TEXT  \\\n",
       "0                                                                                                                                                                                                                                                                     Liputan6.com, Solok: Hingga Rabu (24/10), lebih dari 10 sumur warga di Jorong Tanjung Harapan Nagari Sungai Nanam, Solok, Sumatra Barat, telah tercemar belerang. Hasil penelitian tim Dinas Pertambangan dan Energi Sumbar, pencemaran diakibatkan keluarnya udara panas dari magma Gunung Talang pascagempa 12 September silam. Warga tak berani memakai air untuk kebutuhan sehari-hari karena khawatir keracunan. Dinas Pertambangan dan Energi Sumbar bersama tim Vulkanologi dan Mitigasi Bencana Geologi Bandung masih meneliti penyebab keluarnya hawa panas tersebut. Udara panas bersuhu 61 derajat Celcius dan berbau belerang itu keluar dari lantai rumah milik tiga warga. Saat ini, ketiga rumah itu sudah dikosongkan dan diberi garis polisi [baca: Gunung Talang Mengeluarkan Hawa Panas Beracun]. (YNI/Denni Risman dan Arset Kusnadi).   \n",
       "1  Liputan6.com, Barcelona: Setelah mengalami musim yang buruk pada tahun pertamanya di Spanyol, Thierry Henry membuktikan dirinya masih bertaji. Di bawah pelatih Pep Guardiola sinarnya kembali terang. Titi, panggilan akrabnya, banyak membantu Barcelona menyabet tiga gelar juara bergengsi plus juara Piala Dunia Antarklub di Jepang, Desember silam. Namun begitu, di musim kompetisi sekarang sinar Henry kembali redup. Cedera merongrong membuatnya tidak banyak mendapat kesempatan bermain. Insiden handball ketika membela Prancis yang menyebabkan gol ke gawang Republik Irlandia di babak play-off Piala Dunia 2010 semakin menenggelamkan namanya. Itu semua bermuara pada kabar bahwa dirinya akan hengkang dari Nou Camp, markas Barcelona, setelah perhelatan PD 2010 di Afrika Selatan. Amerika Serikat menjadi persinggahan berikut yang diyakini menjadi pilihan Henry. Kabar itu kian santer kini dan bahkan dikabarkan harian olahraga Katalan, penyerang legendaris Arsenal ini sudah menandatangani prakontrak dengan klub Major League Soccer atau Liga Utama AS, New York Red Bulls. (DIM/Sport).   \n",
       "\n",
       "                                                                                                                                                                                              REFERENCE  \\\n",
       "0  Air sumur warga Tanjung Harapan Nagari Sungai Nanam, Kabupaten Solok, Sumbar, mulai tercemar belerang. Diduga, pencemaran diakibatkan keluarnya udara panas dari magma Gunung Talang di kawasan itu.   \n",
       "1                                                                                          Thierry Henry dikabarkan sudah menandatangani prakontrak dengan klub di Amerika Serikat, New York Red Bulls.   \n",
       "\n",
       "                                                                                                                                                                                                       BERT2GPT  \\\n",
       "0  sekitar 10 sumur warga di jorong tanjung harapan nagari sungai nanam, solok, sumbar, tercemar belerang. pencemaran diakibatkan keluarnya udara panas dari magma gunung talang pascagempa 12 september silam.   \n",
       "1                                                                                                      thierry henry membuktikan dirinya masih bertaji. di bawah pelatih pep guardiola sinarnya kembali terang.   \n",
       "\n",
       "                                                                                                                                                                                                                      T5  \n",
       "0  Lebih dari 10 sumur warga di Jorong Tanjung Harapan Nagari Sungai Nanam, Solok, Sumbar, telah tercemar belerang. Pencemaran diakibatkan keluarnya udara panas dari magma Gunung Talang pascagempa 12 September silam.  \n",
       "1                                                                                                              Thierry Henry membuktikan dirinya masih bertaji. Di bawah bimbingan Pep Guardiola sinarnya kembali redup.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df_compare_res = pd.DataFrame({\n",
    "    \"ORIGINAL TEXT\": sample_train_text[\"clean_article\"],\n",
    "    \"REFERENCE\": sample_train_text[\"clean_summary\"],\n",
    "    \"BERT2GPT\": summaries_bert2gpt,\n",
    "    \"T5\":summaries_t5\n",
    "})\n",
    "\n",
    "df_compare_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280de37-0986-4cc8-967b-dd497c8c479c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "1. Beberapa variasi Rouge menunjukkan model BERT2GPT memiliki score sedikit lebih tinggi dibandingkan T5\n",
    "2. Hasil summary dari BERT2GPT kurang lebih mirip dengan T5\n",
    "3. Di beberapa hasil summary T5 menghasilkan summary yang lebih abstractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b76d123-e685-422b-96d3-aa474fbb937f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
